{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f370f8d-754e-4122-83e1-ba76aa1f0ca6",
   "metadata": {},
   "source": [
    "# Example of generating QAs from an ML book (using LMGQ)\n",
    "\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b61ef3-8030-4e08-8aac-8b39521d0586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n",
      "/opt/conda/envs/1104/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "from uniflow.client import Client\n",
    "from uniflow.flow.constants import (OUTPUT_NAME, QAPAIR_DF_KEY, INPUT_FILE, ERROR_LIST, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bbe2a0",
   "metadata": {},
   "source": [
    "We will need a sapcy package `en_core_web_sm` which is a small English pipeline trained on written web text (blogs, news, comments), that includes vocabulary, syntax and entities. If you haven't installed this package, run the line below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7ce662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03606087-4e11-44cf-897c-4b5c4f509025",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2497d7c-fcee-4de4-a83f-9238360e7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_cur = os.getcwd()\n",
    "# fname = \"umich.txt\"\n",
    "# input_file = os.path.join(f\"{dir_cur}/data/raw_input/\", fname)\n",
    "\n",
    "html_file = \"22.11_information-theory.html\"\n",
    "input_file = os.path.join(f\"{dir_cur}/data/raw_input/\", html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1b6b0e-a1da-489c-afd7-06a21ce8fb03",
   "metadata": {},
   "source": [
    "### synthetic data generation \n",
    "\n",
    "Note it will take about 8 minutes to run this cell if you on a single GPU (V100) machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a23add-52ce-4009-a671-2e8fd32798da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO [preprocess_file_op]: Starting Preprocess HTML...\n",
      "INFO [preprocess_file_op]: Preprocess HTML Complete!\n",
      "INFO [preprocess_text_op]: Preprocessing text content input...\n",
      "INFO [preprocess_text_op]: Preprocessing text content input...Done!\n",
      "INFO [lmqg_op]: Initializing LMQGOp...\n",
      "/opt/conda/envs/1104/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/1104/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/1104/lib/python3.10/site-packages/transformers/modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/1104/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "INFO [lmqg_op]: LMQGOp initialization complete!\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 1 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 650.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1826.79it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 2 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 2341.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2286.97it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 3 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1793.97it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 3: AnswerNotFoundError('Model cannot find any answer candidates in `search`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 4 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1837.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1797.05it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 5 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1837.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1763.05it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 6 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1730.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1784.05it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 7 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1727.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1763.05it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 8 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1778.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3172.70it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 9 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 2608.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1774.24it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 10 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 2079.48it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2029.17it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 11 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1771.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3294.82it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 12 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1672.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1705.00it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 13 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1860.00it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 13: AnswerNotFoundError('Model cannot find any answer candidates in ` 中文版\\n `')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 14 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1683.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1968.23it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 15 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1797.05it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 15: AnswerNotFoundError('Model cannot find any answer candidates in `preface\\ninstallation\\nnotation`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 16 of 237\n",
      "100%|██████████| 7/7 [00:00<00:00, 1885.56it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1909.23it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 17 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1596.39it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1685.31it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 18 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1495.16it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1591.46it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 19 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1495.56it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1591.69it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 20 of 237\n",
      "100%|██████████| 7/7 [00:00<00:00, 1850.74it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1925.25it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 21 of 237\n",
      "100%|██████████| 6/6 [00:00<00:00, 1592.17it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1676.16it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 22 of 237\n",
      "100%|██████████| 9/9 [00:00<00:00, 1387.97it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1466.31it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 23 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1513.92it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1615.21it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 24 of 237\n",
      "100%|██████████| 10/10 [00:00<00:00, 1398.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1442.98it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 25 of 237\n",
      "100%|██████████| 10/10 [00:00<00:00, 1398.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1468.70it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 26 of 237\n",
      "100%|██████████| 13/13 [00:00<00:00, 1586.72it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 1627.74it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 27 of 237\n",
      "100%|██████████| 9/9 [00:00<00:00, 1696.04it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1759.11it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 28 of 237\n",
      "100%|██████████| 16/16 [00:00<00:00, 1133.84it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 1172.68it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 29 of 237\n",
      "100%|██████████| 11/11 [00:00<00:00, 1296.90it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1324.61it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 30 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1282.66it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1275.81it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 31 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 2165.36it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2155.12it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 32 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 2051.00it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2234.10it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 33 of 237\n",
      "100%|██████████| 7/7 [00:00<00:00, 1755.15it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1826.22it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 34 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 2065.40it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2075.10it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 35 of 237\n",
      "100%|██████████| 12/12 [00:00<00:00, 1286.33it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 1336.50it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 36 of 237\n",
      "100%|██████████| 13/13 [00:00<00:00, 1478.19it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 1506.89it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 37 of 237\n",
      "100%|██████████| 10/10 [00:00<00:00, 1462.65it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1508.31it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 38 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1563.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1595.40it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 39 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1761.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1719.68it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 40 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 2647.92it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 40: AnswerNotFoundError('Model cannot find any answer candidates in `preface\\ninstallation\\nnotation`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 41 of 237\n",
      "100%|██████████| 7/7 [00:00<00:00, 1867.10it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1882.78it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 42 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1627.28it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1640.80it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 43 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1558.42it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1562.78it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 44 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1542.02it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1538.98it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 45 of 237\n",
      "100%|██████████| 7/7 [00:00<00:00, 1877.13it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1843.65it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 46 of 237\n",
      "100%|██████████| 6/6 [00:00<00:00, 1650.65it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1651.52it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 47 of 237\n",
      "100%|██████████| 9/9 [00:00<00:00, 1419.87it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1466.08it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 48 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1548.14it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1584.85it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 49 of 237\n",
      "100%|██████████| 10/10 [00:00<00:00, 1442.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1431.94it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 50 of 237\n",
      "100%|██████████| 10/10 [00:00<00:00, 1451.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1447.86it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 51 of 237\n",
      "100%|██████████| 13/13 [00:00<00:00, 1602.15it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 1610.76it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 52 of 237\n",
      "100%|██████████| 9/9 [00:00<00:00, 1701.85it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1762.56it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 53 of 237\n",
      "100%|██████████| 16/16 [00:00<00:00, 1137.57it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 1152.12it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 54 of 237\n",
      "100%|██████████| 11/11 [00:00<00:00, 1318.74it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1321.23it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 55 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1293.24it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1298.83it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 56 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 2210.79it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2155.12it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 57 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 2115.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2065.14it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 58 of 237\n",
      "100%|██████████| 7/7 [00:00<00:00, 1816.84it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1827.70it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 59 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 2105.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2081.80it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 60 of 237\n",
      "100%|██████████| 12/12 [00:00<00:00, 1311.33it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 1329.22it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 61 of 237\n",
      "100%|██████████| 13/13 [00:00<00:00, 1514.74it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 1511.55it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 62 of 237\n",
      "100%|██████████| 10/10 [00:00<00:00, 1511.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1530.27it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 63 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1757.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1746.17it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 64 of 237\n",
      "100%|██████████| 13/13 [00:00<00:00, 499.23it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 507.56it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 65 of 237\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 30/30 [00:00<00:00, 309.74it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 65: OutOfMemoryError('CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 27.38 MiB is free. Including non-PyTorch memory, this process has 15.74 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 161.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 66 of 237\n",
      "100%|██████████| 13/13 [00:00<00:00, 572.94it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 572.60it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 67 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1113.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1177.51it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 68 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1234.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1203.36it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 69 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1669.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1922.23it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 70 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1643.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1795.51it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 71 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1931.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2003.97it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 72 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1797.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1752.01it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 73 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1630.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1670.37it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 74 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1827.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1763.79it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 75 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1798.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1814.15it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 76 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1804.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1852.61it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 77 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1713.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1705.69it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 78 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1769.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1688.53it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 79 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1742.54it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 79: AnswerNotFoundError('Model cannot find any answer candidates in `def nansum(x):\\n return tf.reduce_sum(tf.where(tf.math.is_nan(\\n x), tf.zeros_like(x), x), axis=-1)`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 80 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1735.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2126.93it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 81 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1811.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2686.93it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 82 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1881.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1725.34it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 83 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1297.54it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1419.39it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 84 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 1068.01it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1222.19it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 85 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1029.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1083.80it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 86 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1041.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1124.48it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 87 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1380.16it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1316.07it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 88 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1698.10it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 88: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.3)¶\\\\[h(x) = - e_{x \\\\sim p} [\\\\log p(x)].\\\\]\\nto be specific, if \\\\(x\\\\) is discrete,`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 89 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1398.33it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1524.65it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 90 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1283.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1188.19it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 91 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1575.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1506.57it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 92 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1839.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1698.79it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 93 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1460.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1376.99it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 94 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1679.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1685.81it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 95 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1595.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1743.99it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 96 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1656.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1730.32it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 97 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1261.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1554.02it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 98 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1439.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1589.96it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 99 of 237\n",
      "100%|██████████| 21/21 [00:00<00:00, 389.85it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 99: OutOfMemoryError('CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 95.38 MiB is free. Including non-PyTorch memory, this process has 15.68 GiB memory in use. Of the allocated memory 11.94 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 100 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1441.34it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 100: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.6)¶\\\\[h(s) = \\\\sum_i {p_i \\\\cdot i(s_i)} = - \\\\sum_i {p_i \\\\cdot \\\\log p_i}.\\\\]`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 101 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1373.98it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1387.92it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 102 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1214.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1198.37it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 103 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1226.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1390.68it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 104 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1263.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1361.79it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 105 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1013.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1042.58it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 106 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 785.63it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 795.88it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 107 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1536.38it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1640.32it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 108 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1358.70it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 108: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.9)¶\\\\[h(x, y) = -e_{(x, y) \\\\sim p} [\\\\log p_{x, y}(x, y)].\\\\]\\nprecisely, on the one hand, if \\\\((x, y)\\\\) is a pair of discrete\\nrandom variables, then`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 109 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1451.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1385.63it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 110 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 761.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 760.66it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 111 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1340.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1363.11it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 112 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1842.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1797.82it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 113 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1790.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1851.79it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 114 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1485.76it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1627.28it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 115 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1790.91it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 115: AnswerNotFoundError('Model cannot find any answer candidates in `joint_entropy(np.array([[0.1, 0.5], [0.1, 0.3]]))`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 116 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1890.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1854.25it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 117 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1662.76it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1795.89it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 118 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1759.36it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 118: AnswerNotFoundError('Model cannot find any answer candidates in `joint_entropy(tf.constant([[0.1, 0.5], [0.1, 0.3]]))`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 119 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1642.25it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 119: AnswerNotFoundError('Model cannot find any answer candidates in `notice that this is the same code as before, but now we interpret it\\ndifferently as working on the joint distribution of the two random\\nvariables.`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 120 of 237\n",
      "100%|██████████| 12/12 [00:00<00:00, 610.73it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 613.16it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 121 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1328.43it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 121: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.13)¶\\\\[h(y \\\\mid x) = - e_{(x, y) \\\\sim p} [\\\\log p(y \\\\mid x)],\\\\]\\nwhere \\\\(p(y \\\\mid x) = \\\\frac{p_{x, y}(x, y)}{p_x(x)}\\\\) is the\\nconditional probability. specifically, if \\\\((x, y)\\\\) is a pair of\\ndiscrete random variables, then`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 122 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1323.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1527.98it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 123 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1167.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1165.41it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 124 of 237\n",
      "100%|██████████| 6/6 [00:00<00:00, 845.94it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 802.28it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 125 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1971.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1837.99it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 126 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1891.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1829.18it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 127 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1424.21it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 127: AnswerNotFoundError('Model cannot find any answer candidates in `def conditional_entropy(p_xy, p_x):\\n p_y_given_x = p_xy/p_x\\n cond_ent = -p_xy * np.log2(p_y_given_x)\\n # operator `nansum` will sum up the non-nan number\\n out = nansum(cond_ent.as_nd_ndarray())\\n return out`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 128 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1787.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2029.17it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 129 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1912.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1733.18it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 130 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1454.34it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 130: AnswerNotFoundError('Model cannot find any answer candidates in `def conditional_entropy(p_xy, p_x):\\n p_y_given_x = p_xy/p_x\\n cond_ent = -p_xy * log2(p_y_given_x)\\n # operator `nansum` will sum up the non-nan number\\n out = nansum(cond_ent)\\n return out`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 131 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1813.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1851.79it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 132 of 237\n",
      "100%|██████████| 10/10 [00:00<00:00, 550.87it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 558.01it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 133 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1219.81it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 133: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.17)¶\\\\[i(x, y) = h(x, y) - h(y \\\\mid x) - h(x \\\\mid y).\\\\]\\nindeed, this is a valid definition for the mutual information. if we\\nexpand out the definitions of these terms and combine them, a little\\nalgebra shows that this is the same as`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 134 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1226.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1151.33it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 135 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1521.88it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 135: AnswerNotFoundError('Model cannot find any answer candidates in `\\\\(h(x) - h(x \\\\mid y)\\\\)\\n\\\\(h(y) - h(y \\\\mid x)\\\\)\\n\\\\(h(x) + h(y) - h(x, y)\\\\)`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 136 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1853.02it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1827.58it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 137 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 932.79it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 915.59it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 138 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1718.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2070.24it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 139 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1828.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2005.88it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 140 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1522.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1383.35it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 141 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1678.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1733.18it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 142 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 2989.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2014.56it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 143 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1505.49it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 143: AnswerNotFoundError('Model cannot find any answer candidates in `def mutual_information(p_xy, p_x, p_y):\\n p = p_xy / (p_x * p_y)\\n mutual = p_xy * log2(p)\\n # operator `nansum` will sum up the non-nan number\\n out = nansum(mutual)\\n return out`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 144 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1628.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1678.39it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 145 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1597.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1681.08it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 146 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 982.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 927.74it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 147 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 2296.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1803.23it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 148 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1106.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1248.43it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 149 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 675.88it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 149: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.20)¶\\\\[\\\\textrm{pmi}(x, y) = \\\\log\\\\frac{p_{x, y}(x, y)}{p_x(x) p_y(y)}.\\\\]\\nwe can think of (22.11.20) as measuring how much more or less\\nlikely the specific combination of outcomes \\\\(x\\\\) and \\\\(y\\\\) are\\ncompared to what we would expect for independent random outcomes. if it\\nis large and positive, then these two specific outcomes occur much more\\nfrequently than they would compared to random chance (note: the\\ndenominator is \\\\(p_x(x) p_y(y)\\\\) which is the probability of the two\\noutcomes were independent), whereas if it is large and negative it\\nrepresents the two outcomes happening far less than we would expect by\\nrandom chance.\\nthis allows us to interpret the mutual information\\n(22.11.18) as the average amount that we were surprised\\nto see two outcomes occurring together compared to what we would expect\\nif they were independent.`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 150 of 237\n",
      "100%|██████████| 10/10 [00:00<00:00, 603.00it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 618.14it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 151 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 1032.16it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1108.96it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 152 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1217.50it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1148.34it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 153 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 721.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 684.34it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 154 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1706.39it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 154: AnswerNotFoundError('Model cannot find any answer candidates in `def kl_divergence(p, q):\\n kl = p * np.log2(p / q)\\n out = nansum(kl.as_nd_ndarray())\\n return out.abs().asscalar()`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 155 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1715.46it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 155: AnswerNotFoundError('Model cannot find any answer candidates in `def kl_divergence(p, q):\\n kl = p * log2(p / q)\\n out = nansum(kl)\\n return tf.abs(out).numpy()`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 156 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1748.72it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1741.10it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 157 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1725.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1699.47it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 158 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1673.70it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 158: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.22)¶\\\\[d_{\\\\textrm{kl}}(p\\\\|q) \\\\neq d_{\\\\textrm{kl}}(q\\\\|p).\\\\]`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 159 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 2313.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1752.74it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 160 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1759.36it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 160: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.23)¶\\\\[d_{\\\\textrm{kl}}(p\\\\|q) \\\\geq 0.\\\\]\\nnote that the equality holds only when \\\\(p = q\\\\).`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 161 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1234.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1209.60it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 162 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1344.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1367.11it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 163 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 983.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 947.65it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 164 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1117.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1152.49it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 165 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1598.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1376.99it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 166 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1569.14it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 166: AnswerNotFoundError('Model cannot find any answer candidates in `p = torch.sort(p)[0]\\nq1 = torch.sort(q1)[0]\\nq2 = torch.sort(q2)[0]`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 167 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 2528.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1753.47it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 168 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1536.94it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1516.93it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 169 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1738.57it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1651.63it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 170 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1560.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1416.04it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 171 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 2143.23it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 171: AnswerNotFoundError('Model cannot find any answer candidates in `p = tf.sort(p)\\nq1 = tf.sort(q1)\\nq2 = tf.sort(q2)`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 172 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 939.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 968.59it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 173 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1616.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1648.70it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 174 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1587.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1491.57it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 175 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1529.37it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1580.37it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 176 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1807.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2892.62it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 177 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1651.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1816.50it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 178 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1696.38it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1598.74it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 179 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1863.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1855.07it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 180 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1826.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1855.89it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 181 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1225.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1232.29it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 182 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1702.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2639.59it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 183 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1787.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1807.11it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 184 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1447.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1639.04it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 185 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1705.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1829.98it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 186 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1681.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1819.65it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 187 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1571.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1648.38it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 188 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1736.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1780.26it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 189 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1891.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1690.57it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 190 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 610.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 592.44it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 191 of 237\n",
      "100%|██████████| 6/6 [00:00<00:00, 624.62it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 191: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.24)¶\\\\[\\\\begin{split}\\\\begin{aligned}\\nl(\\\\theta) &= \\\\log l(\\\\theta) \\\\\\\\\\n &= \\\\log \\\\prod_{i=1}^n \\\\pi_i^{y_i} (1 - \\\\pi_i)^{1 - y_i} \\\\\\\\\\n &= \\\\sum_{i=1}^n y_i \\\\log(\\\\pi_i) + (1 - y_i) \\\\log (1 - \\\\pi_i). \\\\\\\\\\n\\\\end{aligned}\\\\end{split}\\\\]\\nmaximizing the log-likelihood function \\\\(l(\\\\theta)\\\\) is identical to\\nminimizing \\\\(- l(\\\\theta)\\\\), and hence we can find the best\\n\\\\(\\\\theta\\\\) from here. to generalize the above loss to any\\ndistributions, we also called \\\\(-l(\\\\theta)\\\\) the cross-entropy\\nloss \\\\(\\\\textrm{ce}(y, \\\\hat{y})\\\\), where \\\\(y\\\\) follows the true\\ndistribution \\\\(p\\\\) and \\\\(\\\\hat{y}\\\\) follows the estimated\\ndistribution \\\\(q\\\\).\\nthis was all derived by working from the maximum likelihood point of\\nview. however, if we look closely we can see that terms like\\n\\\\(\\\\log(\\\\pi_i)\\\\) have entered into our computation which is a solid\\nindication that we can understand the expression from an information\\ntheoretic point of view.`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 192 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1399.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1412.22it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 193 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1184.83it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 193: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.25)¶\\\\[\\\\textrm{ce}(p, q) = - e_{x \\\\sim p} [\\\\log(q(x))].\\\\]\\nby using properties of entropy discussed above, we can also interpret it\\nas the summation of the entropy \\\\(h(p)\\\\) and the kl divergence\\nbetween \\\\(p\\\\) and \\\\(q\\\\), i.e.,`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 194 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1430.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1346.92it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 195 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1655.86it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 195: AnswerNotFoundError('Model cannot find any answer candidates in `def cross_entropy(y_hat, y):\\n ce = -np.log(y_hat[range(len(y_hat)), y])\\n return ce.mean()`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 196 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1314.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1292.15it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 197 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1345.84it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1426.88it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 198 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1651.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1928.42it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 199 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1771.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1711.96it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 200 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1800.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1708.47it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 201 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1781.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1735.33it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 202 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1870.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1924.88it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 203 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1689.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1507.66it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 204 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1790.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1771.99it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 205 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1916.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1860.00it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 206 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1354.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1467.57it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 207 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1341.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1559.22it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 208 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1434.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1488.40it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 209 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 796.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 736.49it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 210 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 991.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 925.49it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 211 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1475.31it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 211: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.28)¶\\\\[\\\\hat{\\\\mathbf{y}}_i= p_{\\\\theta}(\\\\mathbf{y}_i \\\\mid \\\\mathbf{x}_i) = \\\\sum_{j=1}^k y_{ij} p_{\\\\theta} (y_{ij} \\\\mid \\\\mathbf{x}_i).\\\\]\\nhence, the cross-entropy loss would be`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 212 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 784.68it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 212: AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.29)¶\\\\[\\\\begin{split}\\\\textrm{ce}(\\\\mathbf{y}, \\\\hat{\\\\mathbf{y}}) = - \\\\sum_{i=1}^n \\\\mathbf{y}_i \\\\log \\\\hat{\\\\mathbf{y}}_i\\n = - \\\\sum_{i=1}^n \\\\sum_{j=1}^k y_{ij} \\\\log{p_{\\\\theta} (y_{ij} \\\\mid \\\\mathbf{x}_i)}.\\\\\\\\\\\\end{split}\\\\]\\non the other side, we can also approach the problem through maximum\\nlikelihood estimation. to begin with, let’s quickly introduce a\\n\\\\(k\\\\)-class multinoulli distribution. it is an extension of the\\nbernoulli distribution from binary class to multi-class. if a random\\nvariable \\\\(\\\\mathbf{z} = (z_{1}, \\\\ldots, z_{k})\\\\) follows a\\n\\\\(k\\\\)-class multinoulli distribution with probabilities\\n\\\\(\\\\mathbf{p} =\\\\) (\\\\(p_{1}, \\\\ldots, p_{k}\\\\)), i.e.,`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 213 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1296.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1367.11it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 214 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 932.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1051.47it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 215 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 601.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 595.27it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 216 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1685.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1866.62it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 217 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1690.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1605.78it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 218 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1891.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1715.46it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 219 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 943.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 964.28it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 220 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1531.89it/s]\n",
      "WARNING [lmqg_op]: Exception in paragraph 220: AnswerNotFoundError('Model cannot find any answer candidates in `loss = nll_loss(tf.math.log(preds), labels)\\nloss`')\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 221 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1849.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1882.54it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 222 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 2213.35it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2055.02it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 223 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 1135.62it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1166.32it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 224 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1696.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1764.54it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 225 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1213.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1123.88it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 226 of 237\n",
      "100%|██████████| 11/11 [00:00<00:00, 498.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 485.98it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 227 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 1203.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1197.35it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 228 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1572.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1704.31it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 229 of 237\n",
      "100%|██████████| 1/1 [00:00<00:00, 1625.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1685.14it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 230 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 2182.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2169.00it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 231 of 237\n",
      "100%|██████████| 4/4 [00:00<00:00, 1901.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1845.07it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 232 of 237\n",
      "100%|██████████| 8/8 [00:00<00:00, 1701.63it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1700.36it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 233 of 237\n",
      "100%|██████████| 5/5 [00:00<00:00, 1983.50it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1875.14it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 234 of 237\n",
      "100%|██████████| 6/6 [00:00<00:00, 1963.32it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 2002.85it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 235 of 237\n",
      "100%|██████████| 3/3 [00:00<00:00, 2228.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2230.62it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 236 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 2012.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2099.78it/s]\n",
      "INFO [lmqg_op]: Generating question and answer pairs for paragraph 237 of 237\n",
      "100%|██████████| 2/2 [00:00<00:00, 1888.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2447.09it/s]\n",
      "INFO [utils]: Directory '/home/ubuntu/uniflow/example/qa_generation/data/output' already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dict keys: dict_keys(['output', 'root'])\n"
     ]
    }
   ],
   "source": [
    "client = Client(\"flow_data_gen_text\")\n",
    "input_dict = {INPUT_FILE: input_file}\n",
    "input_list = [input_dict]\n",
    "output_list = client.run(input_list)\n",
    "output_dict = output_list[0]\n",
    "\n",
    "print(f\"output_dict keys: {output_dict.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488fc805-b65f-453f-8075-c5ef52aa03c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of output nodes\n",
    "len(output_dict[OUTPUT_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0152c23-6828-4a45-a566-6da92d771c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['QApair_df', 'error_list', 'output_file'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output dictionary keys\n",
    "output_dict[OUTPUT_NAME][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa4141b-8c4e-4789-a0ef-cc5c56833117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the term for a dive into information theory?</td>\n",
       "      <td>deep learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the name of the appendix?</td>\n",
       "      <td>mathematics for deep learningnavigate_next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the name of the appendix?</td>\n",
       "      <td>mathematics for deep learningnavigate_next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What type of theory is used in deep learning?</td>\n",
       "      <td>information theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is a quick search?</td>\n",
       "      <td>quick search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is a code?</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the name of the source?</td>\n",
       "      <td>show source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the name of the preview version?</td>\n",
       "      <td>preview version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the name of the program that runs on a pytorch?</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the name of the website that hosts the internet?</td>\n",
       "      <td>mxnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Question  \\\n",
       "0      What is the term for a dive into information theory?   \n",
       "1                         What is the name of the appendix?   \n",
       "2                         What is the name of the appendix?   \n",
       "3             What type of theory is used in deep learning?   \n",
       "4                                   What is a quick search?   \n",
       "5                                           What is a code?   \n",
       "6                           What is the name of the source?   \n",
       "7                  What is the name of the preview version?   \n",
       "8   What is the name of the program that runs on a pytorch?   \n",
       "9  What is the name of the website that hosts the internet?   \n",
       "\n",
       "                                       Answer  \n",
       "0                               deep learning  \n",
       "1  mathematics for deep learningnavigate_next  \n",
       "2  mathematics for deep learningnavigate_next  \n",
       "3                          information theory  \n",
       "4                                quick search  \n",
       "5                                        code  \n",
       "6                                 show source  \n",
       "7                             preview version  \n",
       "8                                     pytorch  \n",
       "9                                       mxnet  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set this option to None to display full contents of each column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# print the first 10 entries in the generated question-answer pairs.\n",
    "output_dict[OUTPUT_NAME][0][QAPAIR_DF_KEY][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beff7e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/uniflow/example/qa_generation/data/output/output_qa_text_data.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the output file path\n",
    "output_dict[OUTPUT_NAME][0][OUTPUT_FILE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d076c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating QA for 32 paragraphs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'paragraph': 'search',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `search`')\"},\n",
       " {'paragraph': ' 中文版\\n ',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in ` 中文版\\\\n `')\"},\n",
       " {'paragraph': 'preface\\ninstallation\\nnotation',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `preface\\\\ninstallation\\\\nnotation`')\"},\n",
       " {'paragraph': 'preface\\ninstallation\\nnotation',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `preface\\\\ninstallation\\\\nnotation`')\"},\n",
       " {'paragraph': '22.11.1. information¶\\nlet’s start with the “soul” of information theory: information.\\ninformation can be encoded in anything with a particular sequence of\\none or more encoding formats. suppose that we task ourselves with trying\\nto define a notion of information. what could be our starting point?\\nconsider the following thought experiment. we have a friend with a deck\\nof cards. they will shuffle the deck, flip over some cards, and tell us\\nstatements about the cards. we will try to assess the information\\ncontent of each statement.\\nfirst, they flip over a card and tell us, “i see a card.” this provides\\nus with no information at all. we were already certain that this was the\\ncase so we hope the information should be zero.\\nnext, they flip over a card and say, “i see a heart.” this provides us\\nsome information, but in reality there are only \\\\(4\\\\) different\\nsuits that were possible, each equally likely, so we are not surprised\\nby this outcome. we hope that whatever the measure of information, this\\nevent should have low information content.\\nnext, they flip over a card and say, “this is the \\\\(3\\\\) of spades.”\\nthis is more information. indeed there were \\\\(52\\\\) equally likely\\npossible outcomes, and our friend told us which one it was. this should\\nbe a medium amount of information.\\nlet’s take this to the logical extreme. suppose that finally they flip\\nover every card from the deck and read off the entire sequence of the\\nshuffled deck. there are \\\\(52!\\\\) different orders to the deck, again\\nall equally likely, so we need a lot of information to know which one it\\nis.\\nany notion of information we develop must conform to this intuition.\\nindeed, in the next sections we will learn how to compute that these\\nevents have \\\\(0\\\\textrm{ bits}\\\\), \\\\(2\\\\textrm{ bits}\\\\),\\n\\\\(~5.7\\\\textrm{ bits}\\\\), and \\\\(~225.6\\\\textrm{ bits}\\\\) of\\ninformation respectively.\\nif we read through these thought experiments, we see a natural idea. as\\na starting point, rather than caring about the knowledge, we may build\\noff the idea that information represents the degree of surprise or the\\nabstract possibility of the event. for example, if we want to describe\\nan unusual event, we need a lot information. for a common event, we may\\nnot need much information.\\nin 1948, claude e. shannon published a mathematical theory of\\ncommunication (shannon, 1948) establishing the theory of\\ninformation. in his article, shannon introduced the concept of\\ninformation entropy for the first time. we will begin our journey here.',\n",
       "  'error': \"OutOfMemoryError('CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 27.38 MiB is free. Including non-PyTorch memory, this process has 15.74 GiB memory in use. Of the allocated memory 14.59 GiB is allocated by PyTorch, and 161.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\"},\n",
       " {'paragraph': 'def nansum(x):\\n return tf.reduce_sum(tf.where(tf.math.is_nan(\\n x), tf.zeros_like(x), x), axis=-1)',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `def nansum(x):\\\\n return tf.reduce_sum(tf.where(tf.math.is_nan(\\\\n x), tf.zeros_like(x), x), axis=-1)`')\"},\n",
       " {'paragraph': '(22.11.3)¶\\\\[h(x) = - e_{x \\\\sim p} [\\\\log p(x)].\\\\]\\nto be specific, if \\\\(x\\\\) is discrete,',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.3)¶\\\\\\\\[h(x) = - e_{x \\\\\\\\sim p} [\\\\\\\\log p(x)].\\\\\\\\]\\\\nto be specific, if \\\\\\\\(x\\\\\\\\) is discrete,`')\"},\n",
       " {'paragraph': '22.11.2.3. interpretations¶\\nyou may be curious: in the entropy definition (22.11.3), why\\ndo we use an expectation of a negative logarithm? here are some\\nintuitions.\\nfirst, why do we use a logarithm function \\\\(\\\\log\\\\)? suppose that\\n\\\\(p(x) = f_1(x) f_2(x) \\\\ldots, f_n(x)\\\\), where each component\\nfunction \\\\(f_i(x)\\\\) is independent from each other. this means that\\neach \\\\(f_i(x)\\\\) contributes independently to the total information\\nobtained from \\\\(p(x)\\\\). as discussed above, we want the entropy\\nformula to be additive over independent random variables. luckily,\\n\\\\(\\\\log\\\\) can naturally turn a product of probability distributions\\nto a summation of the individual terms.\\nnext, why do we use a negative \\\\(\\\\log\\\\)? intuitively, more\\nfrequent events should contain less information than less common events,\\nsince we often gain more information from an unusual case than from an\\nordinary one. however, \\\\(\\\\log\\\\) is monotonically increasing with the\\nprobabilities, and indeed negative for all values in \\\\([0, 1]\\\\). we\\nneed to construct a monotonically decreasing relationship between the\\nprobability of events and their entropy, which will ideally be always\\npositive (for nothing we observe should force us to forget what we have\\nknown). hence, we add a negative sign in front of \\\\(\\\\log\\\\) function.\\nlast, where does the expectation function come from? consider a random\\nvariable \\\\(x\\\\). we can interpret the self-information\\n(\\\\(-\\\\log(p)\\\\)) as the amount of surprise we have at seeing a\\nparticular outcome. indeed, as the probability approaches zero, the\\nsurprise becomes infinite. similarly, we can interpret the entropy as\\nthe average amount of surprise from observing \\\\(x\\\\). for example,\\nimagine that a slot machine system emits statistical independently\\nsymbols \\\\({s_1, \\\\ldots, s_k}\\\\) with probabilities\\n\\\\({p_1, \\\\ldots, p_k}\\\\) respectively. then the entropy of this system\\nequals to the average self-information from observing each output, i.e.,',\n",
       "  'error': \"OutOfMemoryError('CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 95.38 MiB is free. Including non-PyTorch memory, this process has 15.68 GiB memory in use. Of the allocated memory 11.94 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\"},\n",
       " {'paragraph': '(22.11.6)¶\\\\[h(s) = \\\\sum_i {p_i \\\\cdot i(s_i)} = - \\\\sum_i {p_i \\\\cdot \\\\log p_i}.\\\\]',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.6)¶\\\\\\\\[h(s) = \\\\\\\\sum_i {p_i \\\\\\\\cdot i(s_i)} = - \\\\\\\\sum_i {p_i \\\\\\\\cdot \\\\\\\\log p_i}.\\\\\\\\]`')\"},\n",
       " {'paragraph': '(22.11.9)¶\\\\[h(x, y) = -e_{(x, y) \\\\sim p} [\\\\log p_{x, y}(x, y)].\\\\]\\nprecisely, on the one hand, if \\\\((x, y)\\\\) is a pair of discrete\\nrandom variables, then',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.9)¶\\\\\\\\[h(x, y) = -e_{(x, y) \\\\\\\\sim p} [\\\\\\\\log p_{x, y}(x, y)].\\\\\\\\]\\\\nprecisely, on the one hand, if \\\\\\\\((x, y)\\\\\\\\) is a pair of discrete\\\\nrandom variables, then`')\"},\n",
       " {'paragraph': 'joint_entropy(np.array([[0.1, 0.5], [0.1, 0.3]]))',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `joint_entropy(np.array([[0.1, 0.5], [0.1, 0.3]]))`')\"},\n",
       " {'paragraph': 'joint_entropy(tf.constant([[0.1, 0.5], [0.1, 0.3]]))',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `joint_entropy(tf.constant([[0.1, 0.5], [0.1, 0.3]]))`')\"},\n",
       " {'paragraph': 'notice that this is the same code as before, but now we interpret it\\ndifferently as working on the joint distribution of the two random\\nvariables.',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `notice that this is the same code as before, but now we interpret it\\\\ndifferently as working on the joint distribution of the two random\\\\nvariables.`')\"},\n",
       " {'paragraph': '(22.11.13)¶\\\\[h(y \\\\mid x) = - e_{(x, y) \\\\sim p} [\\\\log p(y \\\\mid x)],\\\\]\\nwhere \\\\(p(y \\\\mid x) = \\\\frac{p_{x, y}(x, y)}{p_x(x)}\\\\) is the\\nconditional probability. specifically, if \\\\((x, y)\\\\) is a pair of\\ndiscrete random variables, then',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.13)¶\\\\\\\\[h(y \\\\\\\\mid x) = - e_{(x, y) \\\\\\\\sim p} [\\\\\\\\log p(y \\\\\\\\mid x)],\\\\\\\\]\\\\nwhere \\\\\\\\(p(y \\\\\\\\mid x) = \\\\\\\\frac{p_{x, y}(x, y)}{p_x(x)}\\\\\\\\) is the\\\\nconditional probability. specifically, if \\\\\\\\((x, y)\\\\\\\\) is a pair of\\\\ndiscrete random variables, then`')\"},\n",
       " {'paragraph': 'def conditional_entropy(p_xy, p_x):\\n p_y_given_x = p_xy/p_x\\n cond_ent = -p_xy * np.log2(p_y_given_x)\\n # operator `nansum` will sum up the non-nan number\\n out = nansum(cond_ent.as_nd_ndarray())\\n return out',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `def conditional_entropy(p_xy, p_x):\\\\n p_y_given_x = p_xy/p_x\\\\n cond_ent = -p_xy * np.log2(p_y_given_x)\\\\n # operator `nansum` will sum up the non-nan number\\\\n out = nansum(cond_ent.as_nd_ndarray())\\\\n return out`')\"},\n",
       " {'paragraph': 'def conditional_entropy(p_xy, p_x):\\n p_y_given_x = p_xy/p_x\\n cond_ent = -p_xy * log2(p_y_given_x)\\n # operator `nansum` will sum up the non-nan number\\n out = nansum(cond_ent)\\n return out',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `def conditional_entropy(p_xy, p_x):\\\\n p_y_given_x = p_xy/p_x\\\\n cond_ent = -p_xy * log2(p_y_given_x)\\\\n # operator `nansum` will sum up the non-nan number\\\\n out = nansum(cond_ent)\\\\n return out`')\"},\n",
       " {'paragraph': '(22.11.17)¶\\\\[i(x, y) = h(x, y) - h(y \\\\mid x) - h(x \\\\mid y).\\\\]\\nindeed, this is a valid definition for the mutual information. if we\\nexpand out the definitions of these terms and combine them, a little\\nalgebra shows that this is the same as',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.17)¶\\\\\\\\[i(x, y) = h(x, y) - h(y \\\\\\\\mid x) - h(x \\\\\\\\mid y).\\\\\\\\]\\\\nindeed, this is a valid definition for the mutual information. if we\\\\nexpand out the definitions of these terms and combine them, a little\\\\nalgebra shows that this is the same as`')\"},\n",
       " {'paragraph': '\\\\(h(x) - h(x \\\\mid y)\\\\)\\n\\\\(h(y) - h(y \\\\mid x)\\\\)\\n\\\\(h(x) + h(y) - h(x, y)\\\\)',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `\\\\\\\\(h(x) - h(x \\\\\\\\mid y)\\\\\\\\)\\\\n\\\\\\\\(h(y) - h(y \\\\\\\\mid x)\\\\\\\\)\\\\n\\\\\\\\(h(x) + h(y) - h(x, y)\\\\\\\\)`')\"},\n",
       " {'paragraph': 'def mutual_information(p_xy, p_x, p_y):\\n p = p_xy / (p_x * p_y)\\n mutual = p_xy * log2(p)\\n # operator `nansum` will sum up the non-nan number\\n out = nansum(mutual)\\n return out',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `def mutual_information(p_xy, p_x, p_y):\\\\n p = p_xy / (p_x * p_y)\\\\n mutual = p_xy * log2(p)\\\\n # operator `nansum` will sum up the non-nan number\\\\n out = nansum(mutual)\\\\n return out`')\"},\n",
       " {'paragraph': '(22.11.20)¶\\\\[\\\\textrm{pmi}(x, y) = \\\\log\\\\frac{p_{x, y}(x, y)}{p_x(x) p_y(y)}.\\\\]\\nwe can think of (22.11.20) as measuring how much more or less\\nlikely the specific combination of outcomes \\\\(x\\\\) and \\\\(y\\\\) are\\ncompared to what we would expect for independent random outcomes. if it\\nis large and positive, then these two specific outcomes occur much more\\nfrequently than they would compared to random chance (note: the\\ndenominator is \\\\(p_x(x) p_y(y)\\\\) which is the probability of the two\\noutcomes were independent), whereas if it is large and negative it\\nrepresents the two outcomes happening far less than we would expect by\\nrandom chance.\\nthis allows us to interpret the mutual information\\n(22.11.18) as the average amount that we were surprised\\nto see two outcomes occurring together compared to what we would expect\\nif they were independent.',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.20)¶\\\\\\\\[\\\\\\\\textrm{pmi}(x, y) = \\\\\\\\log\\\\\\\\frac{p_{x, y}(x, y)}{p_x(x) p_y(y)}.\\\\\\\\]\\\\nwe can think of (22.11.20) as measuring how much more or less\\\\nlikely the specific combination of outcomes \\\\\\\\(x\\\\\\\\) and \\\\\\\\(y\\\\\\\\) are\\\\ncompared to what we would expect for independent random outcomes. if it\\\\nis large and positive, then these two specific outcomes occur much more\\\\nfrequently than they would compared to random chance (note: the\\\\ndenominator is \\\\\\\\(p_x(x) p_y(y)\\\\\\\\) which is the probability of the two\\\\noutcomes were independent), whereas if it is large and negative it\\\\nrepresents the two outcomes happening far less than we would expect by\\\\nrandom chance.\\\\nthis allows us to interpret the mutual information\\\\n(22.11.18) as the average amount that we were surprised\\\\nto see two outcomes occurring together compared to what we would expect\\\\nif they were independent.`')\"},\n",
       " {'paragraph': 'def kl_divergence(p, q):\\n kl = p * np.log2(p / q)\\n out = nansum(kl.as_nd_ndarray())\\n return out.abs().asscalar()',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `def kl_divergence(p, q):\\\\n kl = p * np.log2(p / q)\\\\n out = nansum(kl.as_nd_ndarray())\\\\n return out.abs().asscalar()`')\"},\n",
       " {'paragraph': 'def kl_divergence(p, q):\\n kl = p * log2(p / q)\\n out = nansum(kl)\\n return tf.abs(out).numpy()',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `def kl_divergence(p, q):\\\\n kl = p * log2(p / q)\\\\n out = nansum(kl)\\\\n return tf.abs(out).numpy()`')\"},\n",
       " {'paragraph': '(22.11.22)¶\\\\[d_{\\\\textrm{kl}}(p\\\\|q) \\\\neq d_{\\\\textrm{kl}}(q\\\\|p).\\\\]',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.22)¶\\\\\\\\[d_{\\\\\\\\textrm{kl}}(p\\\\\\\\|q) \\\\\\\\neq d_{\\\\\\\\textrm{kl}}(q\\\\\\\\|p).\\\\\\\\]`')\"},\n",
       " {'paragraph': '(22.11.23)¶\\\\[d_{\\\\textrm{kl}}(p\\\\|q) \\\\geq 0.\\\\]\\nnote that the equality holds only when \\\\(p = q\\\\).',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.23)¶\\\\\\\\[d_{\\\\\\\\textrm{kl}}(p\\\\\\\\|q) \\\\\\\\geq 0.\\\\\\\\]\\\\nnote that the equality holds only when \\\\\\\\(p = q\\\\\\\\).`')\"},\n",
       " {'paragraph': 'p = torch.sort(p)[0]\\nq1 = torch.sort(q1)[0]\\nq2 = torch.sort(q2)[0]',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `p = torch.sort(p)[0]\\\\nq1 = torch.sort(q1)[0]\\\\nq2 = torch.sort(q2)[0]`')\"},\n",
       " {'paragraph': 'p = tf.sort(p)\\nq1 = tf.sort(q1)\\nq2 = tf.sort(q2)',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `p = tf.sort(p)\\\\nq1 = tf.sort(q1)\\\\nq2 = tf.sort(q2)`')\"},\n",
       " {'paragraph': '(22.11.24)¶\\\\[\\\\begin{split}\\\\begin{aligned}\\nl(\\\\theta) &= \\\\log l(\\\\theta) \\\\\\\\\\n &= \\\\log \\\\prod_{i=1}^n \\\\pi_i^{y_i} (1 - \\\\pi_i)^{1 - y_i} \\\\\\\\\\n &= \\\\sum_{i=1}^n y_i \\\\log(\\\\pi_i) + (1 - y_i) \\\\log (1 - \\\\pi_i). \\\\\\\\\\n\\\\end{aligned}\\\\end{split}\\\\]\\nmaximizing the log-likelihood function \\\\(l(\\\\theta)\\\\) is identical to\\nminimizing \\\\(- l(\\\\theta)\\\\), and hence we can find the best\\n\\\\(\\\\theta\\\\) from here. to generalize the above loss to any\\ndistributions, we also called \\\\(-l(\\\\theta)\\\\) the cross-entropy\\nloss \\\\(\\\\textrm{ce}(y, \\\\hat{y})\\\\), where \\\\(y\\\\) follows the true\\ndistribution \\\\(p\\\\) and \\\\(\\\\hat{y}\\\\) follows the estimated\\ndistribution \\\\(q\\\\).\\nthis was all derived by working from the maximum likelihood point of\\nview. however, if we look closely we can see that terms like\\n\\\\(\\\\log(\\\\pi_i)\\\\) have entered into our computation which is a solid\\nindication that we can understand the expression from an information\\ntheoretic point of view.',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.24)¶\\\\\\\\[\\\\\\\\begin{split}\\\\\\\\begin{aligned}\\\\nl(\\\\\\\\theta) &= \\\\\\\\log l(\\\\\\\\theta) \\\\\\\\\\\\\\\\\\\\n &= \\\\\\\\log \\\\\\\\prod_{i=1}^n \\\\\\\\pi_i^{y_i} (1 - \\\\\\\\pi_i)^{1 - y_i} \\\\\\\\\\\\\\\\\\\\n &= \\\\\\\\sum_{i=1}^n y_i \\\\\\\\log(\\\\\\\\pi_i) + (1 - y_i) \\\\\\\\log (1 - \\\\\\\\pi_i). \\\\\\\\\\\\\\\\\\\\n\\\\\\\\end{aligned}\\\\\\\\end{split}\\\\\\\\]\\\\nmaximizing the log-likelihood function \\\\\\\\(l(\\\\\\\\theta)\\\\\\\\) is identical to\\\\nminimizing \\\\\\\\(- l(\\\\\\\\theta)\\\\\\\\), and hence we can find the best\\\\n\\\\\\\\(\\\\\\\\theta\\\\\\\\) from here. to generalize the above loss to any\\\\ndistributions, we also called \\\\\\\\(-l(\\\\\\\\theta)\\\\\\\\) the cross-entropy\\\\nloss \\\\\\\\(\\\\\\\\textrm{ce}(y, \\\\\\\\hat{y})\\\\\\\\), where \\\\\\\\(y\\\\\\\\) follows the true\\\\ndistribution \\\\\\\\(p\\\\\\\\) and \\\\\\\\(\\\\\\\\hat{y}\\\\\\\\) follows the estimated\\\\ndistribution \\\\\\\\(q\\\\\\\\).\\\\nthis was all derived by working from the maximum likelihood point of\\\\nview. however, if we look closely we can see that terms like\\\\n\\\\\\\\(\\\\\\\\log(\\\\\\\\pi_i)\\\\\\\\) have entered into our computation which is a solid\\\\nindication that we can understand the expression from an information\\\\ntheoretic point of view.`')\"},\n",
       " {'paragraph': '(22.11.25)¶\\\\[\\\\textrm{ce}(p, q) = - e_{x \\\\sim p} [\\\\log(q(x))].\\\\]\\nby using properties of entropy discussed above, we can also interpret it\\nas the summation of the entropy \\\\(h(p)\\\\) and the kl divergence\\nbetween \\\\(p\\\\) and \\\\(q\\\\), i.e.,',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.25)¶\\\\\\\\[\\\\\\\\textrm{ce}(p, q) = - e_{x \\\\\\\\sim p} [\\\\\\\\log(q(x))].\\\\\\\\]\\\\nby using properties of entropy discussed above, we can also interpret it\\\\nas the summation of the entropy \\\\\\\\(h(p)\\\\\\\\) and the kl divergence\\\\nbetween \\\\\\\\(p\\\\\\\\) and \\\\\\\\(q\\\\\\\\), i.e.,`')\"},\n",
       " {'paragraph': 'def cross_entropy(y_hat, y):\\n ce = -np.log(y_hat[range(len(y_hat)), y])\\n return ce.mean()',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `def cross_entropy(y_hat, y):\\\\n ce = -np.log(y_hat[range(len(y_hat)), y])\\\\n return ce.mean()`')\"},\n",
       " {'paragraph': '(22.11.28)¶\\\\[\\\\hat{\\\\mathbf{y}}_i= p_{\\\\theta}(\\\\mathbf{y}_i \\\\mid \\\\mathbf{x}_i) = \\\\sum_{j=1}^k y_{ij} p_{\\\\theta} (y_{ij} \\\\mid \\\\mathbf{x}_i).\\\\]\\nhence, the cross-entropy loss would be',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.28)¶\\\\\\\\[\\\\\\\\hat{\\\\\\\\mathbf{y}}_i= p_{\\\\\\\\theta}(\\\\\\\\mathbf{y}_i \\\\\\\\mid \\\\\\\\mathbf{x}_i) = \\\\\\\\sum_{j=1}^k y_{ij} p_{\\\\\\\\theta} (y_{ij} \\\\\\\\mid \\\\\\\\mathbf{x}_i).\\\\\\\\]\\\\nhence, the cross-entropy loss would be`')\"},\n",
       " {'paragraph': '(22.11.29)¶\\\\[\\\\begin{split}\\\\textrm{ce}(\\\\mathbf{y}, \\\\hat{\\\\mathbf{y}}) = - \\\\sum_{i=1}^n \\\\mathbf{y}_i \\\\log \\\\hat{\\\\mathbf{y}}_i\\n = - \\\\sum_{i=1}^n \\\\sum_{j=1}^k y_{ij} \\\\log{p_{\\\\theta} (y_{ij} \\\\mid \\\\mathbf{x}_i)}.\\\\\\\\\\\\end{split}\\\\]\\non the other side, we can also approach the problem through maximum\\nlikelihood estimation. to begin with, let’s quickly introduce a\\n\\\\(k\\\\)-class multinoulli distribution. it is an extension of the\\nbernoulli distribution from binary class to multi-class. if a random\\nvariable \\\\(\\\\mathbf{z} = (z_{1}, \\\\ldots, z_{k})\\\\) follows a\\n\\\\(k\\\\)-class multinoulli distribution with probabilities\\n\\\\(\\\\mathbf{p} =\\\\) (\\\\(p_{1}, \\\\ldots, p_{k}\\\\)), i.e.,',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `(22.11.29)¶\\\\\\\\[\\\\\\\\begin{split}\\\\\\\\textrm{ce}(\\\\\\\\mathbf{y}, \\\\\\\\hat{\\\\\\\\mathbf{y}}) = - \\\\\\\\sum_{i=1}^n \\\\\\\\mathbf{y}_i \\\\\\\\log \\\\\\\\hat{\\\\\\\\mathbf{y}}_i\\\\n = - \\\\\\\\sum_{i=1}^n \\\\\\\\sum_{j=1}^k y_{ij} \\\\\\\\log{p_{\\\\\\\\theta} (y_{ij} \\\\\\\\mid \\\\\\\\mathbf{x}_i)}.\\\\\\\\\\\\\\\\\\\\\\\\end{split}\\\\\\\\]\\\\non the other side, we can also approach the problem through maximum\\\\nlikelihood estimation. to begin with, let’s quickly introduce a\\\\n\\\\\\\\(k\\\\\\\\)-class multinoulli distribution. it is an extension of the\\\\nbernoulli distribution from binary class to multi-class. if a random\\\\nvariable \\\\\\\\(\\\\\\\\mathbf{z} = (z_{1}, \\\\\\\\ldots, z_{k})\\\\\\\\) follows a\\\\n\\\\\\\\(k\\\\\\\\)-class multinoulli distribution with probabilities\\\\n\\\\\\\\(\\\\\\\\mathbf{p} =\\\\\\\\) (\\\\\\\\(p_{1}, \\\\\\\\ldots, p_{k}\\\\\\\\)), i.e.,`')\"},\n",
       " {'paragraph': 'loss = nll_loss(tf.math.log(preds), labels)\\nloss',\n",
       "  'error': \"AnswerNotFoundError('Model cannot find any answer candidates in `loss = nll_loss(tf.math.log(preds), labels)\\\\nloss`')\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out any errors\n",
    "print(f\"Error generating QA for {len(output_dict[OUTPUT_NAME][0][ERROR_LIST])} paragraphs.\")\n",
    "output_dict[OUTPUT_NAME][0][ERROR_LIST]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
