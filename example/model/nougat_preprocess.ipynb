{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbc4c4a",
   "metadata": {},
   "source": [
    "# Example of loading PDF using Nougat\n",
    "Source: https://arxiv.org/abs/1408.5882"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running the code\n",
    "\n",
    "You will need to `uniflow` conda environment to run this notebook. You can set up the environment following the instruction: https://github.com/CambioML/uniflow/tree/main#installation. Furthermore, make sure you have the following packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install nougat-ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from uniflow.client import Client\n",
    "from uniflow.config import Config\n",
    "from uniflow.model.config import OpenAIModelConfig\n",
    "from uniflow.config import NougatConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb677037",
   "metadata": {},
   "source": [
    "### Prepare the input data\n",
    "\n",
    "First, let's set current directory and input data directory, and load the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_cur = os.getcwd()\n",
    "pdf_file = \"1408.5882_page-1.pdf\"\n",
    "input_file = os.path.join(f\"{dir_cur}/data/raw_input/\", pdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the pdf using Nougat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"pdf\": input_file},\n",
    "]\n",
    "\n",
    "config = NougatConfig()\n",
    "nougat_client = Client(config)\n",
    "\n",
    "output = nougat_client.run(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fa833",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = output[0]['output'][0]['response'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to write a little bit prompts to generate question and answer for a given paragraph, each promopt data includes a instruction and a list of examples with \"context\", \"question\" and \"answer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\n",
    "    \"instruction\": \"\"\"Generate one question and its corresponding answer based on the context. Following the format of the examples below to include the same context, question, and answer in the response.\"\"\",\n",
    "    \"examples\": [\n",
    "        {\n",
    "            \"context\": \"\"\"In 1948, Claude E. Shannon published A Mathematical Theory of\\nCommunication (Shannon, 1948) establishing the theory of\\ninformation. In his article, Shannon introduced the concept of\\ninformation entropy for the first time. We will begin our journey here.\"\"\",\n",
    "            \"question\": \"\"\"Who published A Mathematical Theory of Communication in 1948?\"\"\",\n",
    "            \"answer\": \"\"\"Claude E. Shannon.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"context\": p[:1000],\n",
    "            \"question\": \"\"\"\"\"\",\n",
    "            \"answer\": \"\"\"\"\"\",\n",
    "        }\n",
    "    ],\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "In this example, we will use the [OpenAIModelServer](https://github.com/CambioML/uniflow/blob/main/uniflow/model/server.py#L108) as the LLM to generate questions and answers. Let's import the config and client of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model_config=OpenAIModelConfig())\n",
    "client = Client(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call the `run` method on the `client` object to execute the question-answer generation operation on the data shown above.\n",
    "\n",
    "Note sometimes the LLM doesn't return a JSON output, then uniflow will handle the failure and auto retry generating a new output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = client.run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the output\n",
    "\n",
    "Let's take a look of the generation output. We need to do a little postprocessing on the raw output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting context, question, and answer into a DataFrame\n",
    "contexts = []\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for item in output:\n",
    "    for i in item.get('output', []):\n",
    "        for response in i.get('response', []):\n",
    "            if any(key not in response for key in ['context', 'question', 'answer']):\n",
    "                continue\n",
    "            contexts.append(response['context'])\n",
    "            questions.append(response['question'])\n",
    "            answers.append(response['answer'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Context': contexts,\n",
    "    'Question': questions,\n",
    "    'Answer': answers\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', None)  # or use a specific width like 50\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the generated question answers into a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory path you want to ensure exists\n",
    "directory = 'data/output'\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    # Create the directory, including any necessary intermediate directories\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a570e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = df[['Question', 'Answer']]\n",
    "output_df.to_csv(\"data/output/Nike_10k_QApairs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-instruct-ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
